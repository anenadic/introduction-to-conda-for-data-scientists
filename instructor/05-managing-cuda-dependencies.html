<!DOCTYPE html>
<!-- START: inst/pkgdown/templates/layout.html --><!-- Generated by pkgdown: do not edit by hand --><html lang="en" data-bs-theme="auto"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><title>Introduction to Conda for (Data) Scientists: Managing GPU dependencies</title><meta name="viewport" content="width=device-width, initial-scale=1"><script src="../assets/themetoggle.js"></script><link rel="stylesheet" type="text/css" href="../assets/styles.css"><script src="../assets/scripts.js" type="text/javascript"></script><!-- mathjax --><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      config: ["MMLorHTML.js"],
      jax: ["input/TeX","input/MathML","output/HTML-CSS","output/NativeMML", "output/PreviewHTML"],
      extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
      TeX: {
        extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
      },
      tex2jax: {
        inlineMath: [['\\(', '\\)']],
        displayMath: [ ['$$','$$'], ['\\[', '\\]'] ],
        processEscapes: true
      }
    });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><!-- Responsive Favicon for The Carpentries --><link rel="apple-touch-icon" sizes="180x180" href="../favicons/incubator/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="../favicons/incubator/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="../favicons/incubator/favicon-16x16.png"><link rel="manifest" href="../favicons/incubator/site.webmanifest"><link rel="mask-icon" href="../favicons/incubator/safari-pinned-tab.svg" color="#5bbad5"><meta name="msapplication-TileColor" content="#da532c"><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"><meta name="theme-color" media="(prefers-color-scheme: dark)" content="black"></head><body>
    <header id="top" class="navbar navbar-expand-md top-nav incubator"><svg xmlns="http://www.w3.org/2000/svg" class="d-none"><symbol id="check2" viewbox="0 0 16 16"><path d="M13.854 3.646a.5.5 0 0 1 0 .708l-7 7a.5.5 0 0 1-.708 0l-3.5-3.5a.5.5 0 1 1 .708-.708L6.5 10.293l6.646-6.647a.5.5 0 0 1 .708 0z"></path></symbol><symbol id="circle-half" viewbox="0 0 16 16"><path d="M8 15A7 7 0 1 0 8 1v14zm0 1A8 8 0 1 1 8 0a8 8 0 0 1 0 16z"></path></symbol><symbol id="moon-stars-fill" viewbox="0 0 16 16"><path d="M6 .278a.768.768 0 0 1 .08.858 7.208 7.208 0 0 0-.878 3.46c0 4.021 3.278 7.277 7.318 7.277.527 0 1.04-.055 1.533-.16a.787.787 0 0 1 .81.316.733.733 0 0 1-.031.893A8.349 8.349 0 0 1 8.344 16C3.734 16 0 12.286 0 7.71 0 4.266 2.114 1.312 5.124.06A.752.752 0 0 1 6 .278z"></path><path d="M10.794 3.148a.217.217 0 0 1 .412 0l.387 1.162c.173.518.579.924 1.097 1.097l1.162.387a.217.217 0 0 1 0 .412l-1.162.387a1.734 1.734 0 0 0-1.097 1.097l-.387 1.162a.217.217 0 0 1-.412 0l-.387-1.162A1.734 1.734 0 0 0 9.31 6.593l-1.162-.387a.217.217 0 0 1 0-.412l1.162-.387a1.734 1.734 0 0 0 1.097-1.097l.387-1.162zM13.863.099a.145.145 0 0 1 .274 0l.258.774c.115.346.386.617.732.732l.774.258a.145.145 0 0 1 0 .274l-.774.258a1.156 1.156 0 0 0-.732.732l-.258.774a.145.145 0 0 1-.274 0l-.258-.774a1.156 1.156 0 0 0-.732-.732l-.774-.258a.145.145 0 0 1 0-.274l.774-.258c.346-.115.617-.386.732-.732L13.863.1z"></path></symbol><symbol id="sun-fill" viewbox="0 0 16 16"><path d="M8 12a4 4 0 1 0 0-8 4 4 0 0 0 0 8zM8 0a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 0zm0 13a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 13zm8-5a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2a.5.5 0 0 1 .5.5zM3 8a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2A.5.5 0 0 1 3 8zm10.657-5.657a.5.5 0 0 1 0 .707l-1.414 1.415a.5.5 0 1 1-.707-.708l1.414-1.414a.5.5 0 0 1 .707 0zm-9.193 9.193a.5.5 0 0 1 0 .707L3.05 13.657a.5.5 0 0 1-.707-.707l1.414-1.414a.5.5 0 0 1 .707 0zm9.193 2.121a.5.5 0 0 1-.707 0l-1.414-1.414a.5.5 0 0 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .707zM4.464 4.465a.5.5 0 0 1-.707 0L2.343 3.05a.5.5 0 1 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .708z"></path></symbol></svg><a class="visually-hidden-focusable skip-link" href="#main-content">Skip to main content</a>
  <div class="container-fluid top-nav-container">
    <div class="col-md-8">
      <div class="large-logo">
        <img id="incubator-logo" alt="Lesson Description" src="../assets/images/incubator-logo.svg"><span class="badge text-bg-info">
          <abbr title="This lesson is in the beta phase, which means that it is ready for teaching by instructors outside of the original author team.">
            <a href="https://cdh.carpentries.org/the-lesson-life-cycle.html#polishing-beta-stage" class="external-link alert-link">
              <i aria-hidden="true" class="icon" data-feather="alert-circle" style="border-radius: 5px"></i>
              Beta
            </a>
            <span class="visually-hidden">This lesson is in the beta phase, which means that it is ready for teaching by instructors outside of the original author team.</span>
          </abbr>
        </span>

      </div>
    </div>
    <div class="selector-container">
      <div id="theme-selector">
        <li class="nav-item dropdown" id="theme-button-list">
          <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
            <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="bd-theme-text"><li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                Light
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                Dark
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                Auto
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
          </ul></li>
      </div>

      <div class="dropdown" id="instructor-dropdown">
        <button class="btn btn-secondary dropdown-toggle bordered-button" type="button" id="dropdownMenu1" data-bs-toggle="dropdown" aria-expanded="false">
          <i aria-hidden="true" class="icon" data-feather="eye"></i> Instructor View <i data-feather="chevron-down"></i>
        </button>
        <ul class="dropdown-menu" aria-labelledby="dropdownMenu1"><li><button class="dropdown-item" type="button" onclick="window.location.href='../05-managing-cuda-dependencies.html';">Learner View</button></li>
        </ul></div>
    </div>
  </div>
  <hr></header><nav class="navbar navbar-expand-xl bottom-nav incubator" aria-label="Main Navigation"><div class="container-fluid nav-container">
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle Navigation">
      <span class="navbar-toggler-icon"></span>
      <span class="menu-title">Menu</span>
    </button>
    <div class="nav-logo">
      <img class="small-logo" alt="Lesson Description" src="../assets/images/incubator-logo-sm.svg"></div>
    <div class="lesson-title-md">
      Introduction to Conda for (Data) Scientists
    </div>
    <div class="search-icon-sm">
      <!-- TODO: do not show until we have search
        <i role="img" aria-label="Search the All In One page" data-feather="search"></i>
      -->
    </div>
    <div class="desktop-nav">
      <ul class="navbar-nav me-auto mb-2 mb-lg-0"><li class="nav-item">
          <span class="lesson-title">
            Introduction to Conda for (Data) Scientists
          </span>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/key-points.html">Key Points</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/instructor-notes.html">Instructor Notes</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/images.html">Extract All Images</a>
        </li>
        <li class="nav-item dropdown">
          <button class="nav-link dropdown-toggle" id="navbarDropdown" data-bs-toggle="dropdown" aria-expanded="false">
            More <i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu" aria-labelledby="navbarDropdown"><hr><li><a class="dropdown-item" href="discuss.html">Discussion</a></li><li><a class="dropdown-item" href="reference.html">Glossary</a></li>
          </ul></li>
      </ul></div>
    <!--
    <form class="d-flex col-md-2 search-form">
      <fieldset disabled>
      <input class="form-control me-2 searchbox" type="search" placeholder="" aria-label="">
        <button class="btn btn-outline-success tablet-search-button"  type="submit">
          <i class="search-icon" data-feather="search" role="img" aria-label="Search the All In One page"></i>
        </button>
      </fieldset>
    </form>
    -->
    <a id="search-button" class="btn btn-primary" href="../instructor/aio.html" role="button" aria-label="Search the All In One page">Search the All In One page</a>
  </div><!--/div.container-fluid -->
</nav><div class="col-md-12 mobile-title">
  Introduction to Conda for (Data) Scientists
</div>

<aside class="col-md-12 lesson-progress"><div style="width: 74%" class="percentage">
    74%
  </div>
  <div class="progress incubator">
    <div class="progress-bar incubator" role="progressbar" style="width: 74%" aria-valuenow="74" aria-label="Lesson Progress" aria-valuemin="0" aria-valuemax="100">
    </div>
  </div>
</aside><div class="container">
      <div class="row">
        <!-- START: inst/pkgdown/templates/navbar.html -->
<div id="sidebar-col" class="col-lg-4">
  <div id="sidebar" class="sidebar">
      <nav aria-labelledby="flush-headingEleven"><button role="button" aria-label="close menu" alt="close menu" aria-expanded="true" aria-controls="sidebar" class="collapse-toggle" data-collapse="Collapse " data-episodes="Episodes ">
          <i class="search-icon" data-feather="x" role="img"></i>
        </button>
        <div class="sidebar-inner">
          <div class="row mobile-row" id="theme-row-mobile">
            <div class="col" id="theme-selector">
              <li class="nav-item dropdown" id="theme-button-list">
                <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
                  <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><span class="d-lg-none ms-1" id="bd-theme-text">Toggle Theme</span>
                </button>
                <ul class="dropdown-menu dropdown-menu-right" aria-labelledby="bd-theme-text"><li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                      Light
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                      Dark
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                      <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                      Auto
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                </ul></li>
            </div>
          </div>
          <div class="row mobile-row">
            <div class="col">
              <div class="sidenav-view-selector">
                <div class="accordion accordion-flush" id="accordionFlush9">
                  <div class="accordion-item">
                    <h2 class="accordion-header" id="flush-headingNine">
                      <button class="accordion-button collapsed" id="instructor" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseNine" aria-expanded="false" aria-controls="flush-collapseNine">
                        <i id="eye" aria-hidden="true" class="icon" data-feather="eye"></i> Instructor View
                      </button>
                    </h2>
                    <div id="flush-collapseNine" class="accordion-collapse collapse" aria-labelledby="flush-headingNine" data-bs-parent="#accordionFlush2">
                      <div class="accordion-body">
                        <a href="../05-managing-cuda-dependencies.html">Learner View</a>
                      </div>
                    </div>
                  </div><!--/div.accordion-item-->
                </div><!--/div.accordion-flush-->
              </div><!--div.sidenav-view-selector -->
            </div><!--/div.col -->

            <hr></div><!--/div.mobile-row -->

          <div class="accordion accordion-flush" id="accordionFlush11">
            <div class="accordion-item">

              <button id="chapters" class="accordion-button show" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseEleven" aria-expanded="false" aria-controls="flush-collapseEleven">
                <h2 class="accordion-header chapters" id="flush-headingEleven">
                  EPISODES
                </h2>
              </button>
              <div id="flush-collapseEleven" class="accordion-collapse show collapse" aria-labelledby="flush-headingEleven" data-bs-parent="#accordionFlush11">

                <div class="accordion-body">
                  <div class="accordion accordion-flush" id="accordionFlush1">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading1">
        <a href="index.html">Summary and Schedule</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush2">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading2">
        <a href="01-getting-started-with-conda.html">1. Getting Started with Conda</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush3">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading3">
        <a href="02-working-with-environments.html">2. Working with Environments</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush4">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading4">
        <a href="03-using-packages-and-channels.html">3. Using Packages and Channels</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush5">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading5">
        <a href="04-sharing-environments.html">4. Sharing Environments</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlushcurrent">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-headingcurrent">
      <button class="accordion-button" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapsecurrent" aria-expanded="true" aria-controls="flush-collapsecurrent">
        <span class="visually-hidden">Current Chapter</span>
        <span class="current-chapter">
        5. Managing GPU dependencies
        </span>
      </button>
    </div><!--/div.accordion-header-->

    <div id="flush-collapsecurrent" class="accordion-collapse collapse show" aria-labelledby="flush-headingcurrent" data-bs-parent="#accordionFlushcurrent">
      <div class="accordion-body">
        <ul><li><a href="#getting-familiar-with-nvidia-cuda-libraries">Getting familiar with NVIDIA CUDA libraries</a></li>
<li><a href="#some-example-conda-environment-files">Some example Conda environment files</a></li>
<li><a href="#but-what-if-i-need-the-nvidia-cuda-compiler">But what if I need the NVIDIA CUDA Compiler?</a></li>
        </ul></div><!--/div.accordion-body-->
    </div><!--/div.accordion-collapse-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

                </div>
              </div>
            </div>

            <hr class="half-width"><div class="accordion accordion-flush lesson-resources" id="accordionFlush12">
              <div class="accordion-item">
                <h2 class="accordion-header" id="flush-headingTwelve">
                  <button class="accordion-button collapsed" id="lesson-resources" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseTwelve" aria-expanded="false" aria-controls="flush-collapseTwelve">
                    RESOURCES
                  </button>
                </h2>
                <div id="flush-collapseTwelve" class="accordion-collapse collapse" aria-labelledby="flush-headingTwelve" data-bs-parent="#accordionFlush12">
                  <div class="accordion-body">
                    <ul><li>
                        <a href="../instructor/key-points.html">Key Points</a>
                      </li>
                      <li>
                        <a href="../instructor/instructor-notes.html">Instructor Notes</a>
                      </li>
                      <li>
                        <a href="../instructor/images.html">Extract All Images</a>
                      </li>
                      <hr><li><a class="dropdown-item" href="discuss.html">Discussion</a></li><li><a class="dropdown-item" href="reference.html">Glossary</a></li>
                    </ul></div>
                </div>
              </div>
            </div>
            <hr class="half-width lesson-resources"><a href="../instructor/aio.html">See all in one page</a>


            <hr class="d-none d-sm-block d-md-none"><div class="d-grid gap-1">

            </div>
          </div><!-- /div.accordion -->
        </div><!-- /div.sidebar-inner -->
      </nav></div><!-- /div.sidebar -->
  </div><!-- /div.sidebar-col -->
<!-- END:   inst/pkgdown/templates/navbar.html-->

        <!-- START: inst/pkgdown/templates/content-instructor.html -->
  <div class="col-xl-8 col-lg-12 primary-content">
    <nav class="lesson-content mx-md-4" aria-label="Previous and Next Chapter"><!-- content for small screens --><div class="d-block d-sm-block d-md-none">
        <a class="chapter-link" href="../instructor/04-sharing-environments.html"><i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>Previous</a>
        <a class="chapter-link float-end" href="../instructor/index.html">Next<i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i></a>
      </div>
      <!-- content for large screens -->
      <div class="d-none d-sm-none d-md-block">
        <a class="chapter-link" href="../instructor/04-sharing-environments.html" rel="prev">
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>
          Previous: Sharing Environments
        </a>
        <a class="chapter-link float-end" href="../instructor/index.html" rel="next">
          Home
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i>
        </a>
      </div>
      <hr></nav><main id="main-content" class="main-content"><div class="container lesson-content">
        <h1>Managing GPU dependencies</h1>
        <p>Last updated on 2024-11-15 |

        <a href="https://github.com/carpentries-incubator/introduction-to-conda-for-data-scientists/edit/main/episodes/05-managing-cuda-dependencies.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>



        <p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 60 minutes</p>

        <div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>

        

<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul><li>Which NVIDIA libraries are available via Conda?</li>
<li>What do you do when you need the NVIDIA CUDA Compiler (NVCC) for
your project?</li>
</ul></div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul><li>Show how to use Conda to manage key GPU dependencies for you next
(data) science project.</li>
<li>Show how to identify which versions of CUDA packages are available
via Conda.</li>
<li>Understand how to write a Conda environment file for a project with
GPU dependencies.</li>
<li>Understand when you need the NVIDIA CUDA Compiler (NVCC) and how to
handle this situation.</li>
</ul></div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="getting-familiar-with-nvidia-cuda-libraries">Getting familiar with NVIDIA CUDA libraries<a class="anchor" aria-label="anchor" href="#getting-familiar-with-nvidia-cuda-libraries"></a></h2>
<hr class="half-width"><p>Transitioning your (data) science projects from CPU to GPU can seem
like a daunting task. In particular, there is quite a bit of unfamiliar
additional software, such as <a href="https://developer.nvidia.com/cuda-toolkit" class="external-link">NVIDIA CUDA
Toolkit</a>, <a href="https://developer.nvidia.com/nccl" class="external-link">NVIDIA
Collective Communications Library (NCCL)</a>, and <a href="https://developer.nvidia.com/cudnn" class="external-link">NVIDIA Deep Neural Network
Library (cuDNN)</a> to download and install.</p>
<p>If you go to the <a href="https://developer.nvidia.com/" class="external-link">NVIDIA
developer</a> website you will find loads of documentation and
instructions for how to install these libraries system wide. But then
what do you do if you need different versions of these new libraries for
different projects? You could install a bunch of different versions of
NVIDIA CUDA Toolkit, NCCL, and cuDNN system wide and then use
environment variables to control the “active” versions for each project
but this is cumbersome and error prone. Fortunately there are better
ways!</p>
<p>In this episode we are going to see how to manage project specific
versions of the NVIDIA CUDA Toolkit, NCCL, and cuDNN using Conda.</p>
<div class="section level3">
<h3 id="are-nvidia-libraries-available-via-conda">Are NVIDIA libraries available via Conda?<a class="anchor" aria-label="anchor" href="#are-nvidia-libraries-available-via-conda"></a></h3>
<p>Yep! The most important NVIDIA CUDA library that you will need is the
NVIDIA CUDA Toolkit. The NVIDIA CUDA Toolkit provides a development
environment for creating high performance GPU-accelerated applications.
The toolkit includes GPU-accelerated libraries, debugging and
optimization tools and a runtime library. You can use the
<code>conda search</code> command to see what versions of the NVIDIA
CUDA Toolkit are available from the default channels.</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="ex">$</span> conda search cudatoolkit</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="ex">Loading</span> channels: done</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="co"># Name                       Version           Build  Channel</span></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="ex">cudatoolkit</span>                      9.0      h13b8566_0  pkgs/main</span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a><span class="ex">cudatoolkit</span>                      9.2               0  pkgs/main</span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a><span class="ex">cudatoolkit</span>                 10.0.130               0  pkgs/main</span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a><span class="ex">cudatoolkit</span>                 10.1.168               0  pkgs/main</span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a><span class="ex">cudatoolkit</span>                 10.1.243      h6bb024c_0  pkgs/main</span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a><span class="ex">cudatoolkit</span>                  10.2.89      hfd86e86_0  pkgs/main</span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a><span class="ex">cudatoolkit</span>                  10.2.89      hfd86e86_1  pkgs/main</span></code></pre>
</div>
<p>NVIDIA actually maintains their own Conda channel and the versions of
CUDA Toolkit available from the default channels are the same as those
you will find on the NVIDIA channel. If you are interested in confirming
this you can run the command</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="ex">$</span> conda search <span class="at">--channel</span> nvidia cudatoolkit</span></code></pre>
</div>
<p>and then compare the build numbers with those listed above from the
default channels.</p>
<div id="the-cuda-toolkit-packages-available-from-defaults-do-not-include-nvcc" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="the-cuda-toolkit-packages-available-from-defaults-do-not-include-nvcc" class="callout-inner">
<h3 class="callout-title">The CUDA Toolkit packages available from defaults do not include NVCC</h3>
<div class="callout-content">
<p>An important limitation of the versions of the NVIDIA CUDA Toolkit
that are available from the either the default or NVIDIA Conda channels
is that they do not include the NVIDIA CUDA Compiler (NVCC).</p>
</div>
</div>
</div>
<div class="section level4">
<h4 id="what-about-cudnn">What about cuDNN?<a class="anchor" aria-label="anchor" href="#what-about-cudnn"></a></h4>
<p>The <a href="https://developer.nvidia.com/cudnn" class="external-link">NVIDIA CUDA Deep
Neural Network library (cuDNN)</a> is a GPU-accelerated library of
primitives for deep neural networks. cuDNN provides highly tuned
implementations for standard routines such as forward and backward
convolution, pooling, normalization, and activation layers.</p>
<p>If you are interested in deep learning, then you will need to get
your hands on cuDNN. Various versions of cuDNN are available from the
default channels.</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="ex">$</span> conda search cudnn</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a><span class="ex">Loading</span> channels: done</span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a><span class="co"># Name                       Version           Build  Channel</span></span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a><span class="ex">cudnn</span>                          7.0.5       cuda8.0_0  pkgs/main</span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a><span class="ex">cudnn</span>                          7.1.2       cuda9.0_0  pkgs/main</span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a><span class="ex">cudnn</span>                          7.1.3       cuda8.0_0  pkgs/main</span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a><span class="ex">cudnn</span>                          7.2.1       cuda9.2_0  pkgs/main</span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a><span class="ex">cudnn</span>                          7.3.1      cuda10.0_0  pkgs/main</span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a><span class="ex">cudnn</span>                          7.3.1       cuda9.0_0  pkgs/main</span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a><span class="ex">cudnn</span>                          7.3.1       cuda9.2_0  pkgs/main</span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a><span class="ex">cudnn</span>                          7.6.0      cuda10.0_0  pkgs/main</span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a><span class="ex">cudnn</span>                          7.6.0      cuda10.1_0  pkgs/main</span>
<span id="cb3-15"><a href="#cb3-15" tabindex="-1"></a><span class="ex">cudnn</span>                          7.6.0       cuda9.0_0  pkgs/main</span>
<span id="cb3-16"><a href="#cb3-16" tabindex="-1"></a><span class="ex">cudnn</span>                          7.6.0       cuda9.2_0  pkgs/main</span>
<span id="cb3-17"><a href="#cb3-17" tabindex="-1"></a><span class="ex">cudnn</span>                          7.6.4      cuda10.0_0  pkgs/main</span>
<span id="cb3-18"><a href="#cb3-18" tabindex="-1"></a><span class="ex">cudnn</span>                          7.6.4      cuda10.1_0  pkgs/main</span>
<span id="cb3-19"><a href="#cb3-19" tabindex="-1"></a><span class="ex">cudnn</span>                          7.6.4       cuda9.0_0  pkgs/main</span>
<span id="cb3-20"><a href="#cb3-20" tabindex="-1"></a><span class="ex">cudnn</span>                          7.6.4       cuda9.2_0  pkgs/main</span>
<span id="cb3-21"><a href="#cb3-21" tabindex="-1"></a><span class="ex">cudnn</span>                          7.6.5      cuda10.0_0  pkgs/main</span>
<span id="cb3-22"><a href="#cb3-22" tabindex="-1"></a><span class="ex">cudnn</span>                          7.6.5      cuda10.1_0  pkgs/main</span>
<span id="cb3-23"><a href="#cb3-23" tabindex="-1"></a><span class="ex">cudnn</span>                          7.6.5      cuda10.2_0  pkgs/main</span>
<span id="cb3-24"><a href="#cb3-24" tabindex="-1"></a><span class="ex">cudnn</span>                          7.6.5       cuda9.0_0  pkgs/main</span>
<span id="cb3-25"><a href="#cb3-25" tabindex="-1"></a><span class="ex">cudnn</span>                          7.6.5       cuda9.2_0  pkgs/main</span></code></pre>
</div>
</div>
</div>
<div class="section level3">
<h3 id="what-about-nccl">What about NCCL?<a class="anchor" aria-label="anchor" href="#what-about-nccl"></a></h3>
<p>If you are already accelerating your (data) science workflows with a
GPU, then in the near future you will probably be interested in using
more than one GPU. The <a href="https://developer.nvidia.com/nccl" class="external-link">NVIDIA Collective
Communications Library (NCCL)</a> implements multi-GPU and multi-node
collective communication primitives that are performance optimized for
NVIDIA GPUs.</p>
<p>There are some older versions of NCCL available from the default
channels but these versions will not be useful (unless, perhaps, you are
forced to use very old versions of TensorFlow or similar).</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="ex">$</span> conda search nccl</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a><span class="ex">Loading</span> channels: done</span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a><span class="co"># Name                       Version           Build  Channel</span></span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a><span class="ex">nccl</span>                           1.3.5      cuda10.0_0  pkgs/main</span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a><span class="ex">nccl</span>                           1.3.5       cuda9.0_0  pkgs/main</span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a><span class="ex">nccl</span>                           1.3.5       cuda9.2_0  pkgs/main</span></code></pre>
</div>
<p>Not to worry: Conda Forge to the rescue! <a href="https://conda-forge.org/" class="external-link">Conda Forge</a> is a community-led
collection of recipes, build infrastructure and distributions for the
Conda package manager. I always check the <code>conda-forge</code>
channel when I can’t find something I need available on the default
channels.</p>
<div id="which-version-of-nccl-are-available-via-conda-forge" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="which-version-of-nccl-are-available-via-conda-forge" class="callout-inner">
<h3 class="callout-title">Which version of NCCL are available via Conda Forge?</h3>
<div class="callout-content">
<p>Find out which versions of the NVIDIA Collective Communications
Library (NCCL) are available via Conda Forge?</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<p>Use the <code>conda search</code> command with the
<code>--channel conda-forge</code> option.</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="ex">$</span> conda search <span class="at">--channel</span> conda-forge nccl</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a><span class="ex">Loading</span> channels: done</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a><span class="co"># Name                       Version           Build  Channel</span></span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a><span class="ex">nccl</span>                           1.3.5      cuda10.0_0  pkgs/main</span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a><span class="ex">nccl</span>                           1.3.5       cuda9.0_0  pkgs/main</span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a><span class="ex">nccl</span>                           1.3.5       cuda9.2_0  pkgs/main</span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a><span class="ex">nccl</span>                         2.4.6.1      h51cf6c1_0  conda-forge</span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a><span class="ex">nccl</span>                         2.4.6.1      h7cc98d6_0  conda-forge</span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a><span class="ex">nccl</span>                         2.4.6.1      hc6a2c23_0  conda-forge</span>
<span id="cb5-12"><a href="#cb5-12" tabindex="-1"></a><span class="ex">nccl</span>                         2.4.6.1      hd6f8bf8_0  conda-forge</span>
<span id="cb5-13"><a href="#cb5-13" tabindex="-1"></a><span class="ex">nccl</span>                         2.4.7.1      h51cf6c1_0  conda-forge</span>
<span id="cb5-14"><a href="#cb5-14" tabindex="-1"></a><span class="ex">nccl</span>                         2.4.7.1      h7cc98d6_0  conda-forge</span>
<span id="cb5-15"><a href="#cb5-15" tabindex="-1"></a><span class="ex">nccl</span>                         2.4.7.1      hd6f8bf8_0  conda-forge</span>
<span id="cb5-16"><a href="#cb5-16" tabindex="-1"></a><span class="ex">nccl</span>                         2.4.8.1      h51cf6c1_0  conda-forge</span>
<span id="cb5-17"><a href="#cb5-17" tabindex="-1"></a><span class="ex">nccl</span>                         2.4.8.1      h51cf6c1_1  conda-forge</span>
<span id="cb5-18"><a href="#cb5-18" tabindex="-1"></a><span class="ex">nccl</span>                         2.4.8.1      h7cc98d6_0  conda-forge</span>
<span id="cb5-19"><a href="#cb5-19" tabindex="-1"></a><span class="ex">nccl</span>                         2.4.8.1      h7cc98d6_1  conda-forge</span>
<span id="cb5-20"><a href="#cb5-20" tabindex="-1"></a><span class="ex">nccl</span>                         2.4.8.1      hd6f8bf8_0  conda-forge</span>
<span id="cb5-21"><a href="#cb5-21" tabindex="-1"></a><span class="ex">nccl</span>                         2.4.8.1      hd6f8bf8_1  conda-forge</span>
<span id="cb5-22"><a href="#cb5-22" tabindex="-1"></a><span class="ex">nccl</span>                         2.5.6.1      h51cf6c1_0  conda-forge</span>
<span id="cb5-23"><a href="#cb5-23" tabindex="-1"></a><span class="ex">nccl</span>                         2.5.6.1      h7cc98d6_0  conda-forge</span>
<span id="cb5-24"><a href="#cb5-24" tabindex="-1"></a><span class="ex">nccl</span>                         2.5.6.1      hc6a2c23_0  conda-forge</span>
<span id="cb5-25"><a href="#cb5-25" tabindex="-1"></a><span class="ex">nccl</span>                         2.5.6.1      hd6f8bf8_0  conda-forge</span>
<span id="cb5-26"><a href="#cb5-26" tabindex="-1"></a><span class="ex">nccl</span>                         2.5.7.1      h51cf6c1_0  conda-forge</span>
<span id="cb5-27"><a href="#cb5-27" tabindex="-1"></a><span class="ex">nccl</span>                         2.5.7.1      h7cc98d6_0  conda-forge</span>
<span id="cb5-28"><a href="#cb5-28" tabindex="-1"></a><span class="ex">nccl</span>                         2.5.7.1      hc6a2c23_0  conda-forge</span>
<span id="cb5-29"><a href="#cb5-29" tabindex="-1"></a><span class="ex">nccl</span>                         2.5.7.1      hd6f8bf8_0  conda-forge</span>
<span id="cb5-30"><a href="#cb5-30" tabindex="-1"></a><span class="ex">nccl</span>                         2.6.4.1      h51cf6c1_0  conda-forge</span>
<span id="cb5-31"><a href="#cb5-31" tabindex="-1"></a><span class="ex">nccl</span>                         2.6.4.1      h7cc98d6_0  conda-forge</span>
<span id="cb5-32"><a href="#cb5-32" tabindex="-1"></a><span class="ex">nccl</span>                         2.6.4.1      hc6a2c23_0  conda-forge</span>
<span id="cb5-33"><a href="#cb5-33" tabindex="-1"></a><span class="ex">nccl</span>                         2.6.4.1      hd6f8bf8_0  conda-forge</span></code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="some-example-conda-environment-files">Some example Conda environment files<a class="anchor" aria-label="anchor" href="#some-example-conda-environment-files"></a></h2>
<hr class="half-width"><p>Now that you know how to figure out which versions of the various
NVIDIA CUDA libraries are available on which channels you are ready to
write your environment.yml file. In this section I will provide some
example Conda environment files for PyTorch, TensorFlow, and NVIDIA
RAPIDS to help get you started on your next GPU data science
project.</p>
<div class="section level3">
<h3 id="pytorch">PyTorch<a class="anchor" aria-label="anchor" href="#pytorch"></a></h3>
<p><a href="https://pytorch.org/" class="external-link">PyTorch</a> is an open source machine
learning library based on the Torch library, used for applications such
as computer vision and natural language processing. It is primarily
developed by Facebook’s AI Research lab. Conda is actually the <a href="https://pytorch.org/get-started/locally/" class="external-link">recommended way</a> to
install PyTorch. The official PyTorch binary ships with NCCL and cuDNN
so it is not necessary to include these libraries in your
<code>environment.yml</code> file (unless some other package also needs
these libraries!).</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">YAML<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode yaml" tabindex="0"><code class="sourceCode yaml"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="fu">name</span><span class="kw">:</span><span class="at"> </span><span class="ch">null</span></span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a><span class="fu">channels</span><span class="kw">:</span></span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> pytorch</span></span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> conda-forge</span></span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> defaults</span></span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a></span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a><span class="fu">dependencies</span><span class="kw">:</span></span>
<span id="cb6-9"><a href="#cb6-9" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> cudatoolkit=10.1</span></span>
<span id="cb6-10"><a href="#cb6-10" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> pip=20.0</span></span>
<span id="cb6-11"><a href="#cb6-11" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> python=3.7</span></span>
<span id="cb6-12"><a href="#cb6-12" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> pytorch=1.5</span></span>
<span id="cb6-13"><a href="#cb6-13" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> torchvision=0.6</span></span></code></pre>
</div>
<div id="check-your-channel-priorities" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="check-your-channel-priorities" class="callout-inner">
<h3 class="callout-title">Check your channel priorities!</h3>
<div class="callout-content">
<p>Also take note of the channel priorities: the official
<code>pytorch</code> channel must be given priority over
<code>conda-forge</code> in order to insure that the official PyTorch
binaries (the ones that include NCCL and cuDNN) will be installed
(otherwise you will get some unofficial version of PyTorch available on
<code>conda-forge</code>).</p>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="tensorflow">TensorFlow<a class="anchor" aria-label="anchor" href="#tensorflow"></a></h3>
<p><a href="https://www.tensorflow.org/" class="external-link">TensorFlow</a> is a free,
open-source software library for dataflow and differentiable programming
across a range of tasks. It is a symbolic math library, and is also used
for machine learning applications such as neural networks. There are
lots of versions and builds of TensorFlow available via Conda (the
output of <code>conda search tensorflow</code> is too long to share
here!).</p>
<p>How do you decide which version is the “correct” version? How to make
sure that you get a build that includes GPU support? At this point you
have seen all the Conda “tricks” required to solve this one
yourself!</p>
<div id="create-an-environment.yml-file-for-tensorflow" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="create-an-environment.yml-file-for-tensorflow" class="callout-inner">
<h3 class="callout-title">Create an <code>environment.yml</code> file
for TensorFlow</h3>
<div class="callout-content">
<p>In this exercise you will create a Conda environment for TensorFlow.
Important CUDA dependencies of TensorFlow are the CUDA Toolkit, cuDNN,
and <a href="https://docs.nvidia.com/cuda/cupti/index.html" class="external-link">CUPTI</a>.
Don’t forget that if you want to train on more than one GPU, then your
environment will also need NCCL and an MPI implementation.</p>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2"> Show me the solution </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" aria-labelledby="headingSolution2" data-bs-parent="#accordionSolution2">
<div class="accordion-body">
<p>Use the <code>tensorflow-gpu</code> meta-package to select the
appropriate version and build of TensorFlow for your OS; use <a href="https://mpi4py.readthedocs.io/en/stable/" class="external-link"><code>mpi4py</code></a>
to get a CUDA-aware OpenMPI build.</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">YAML<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode yaml" tabindex="0"><code class="sourceCode yaml"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="fu">name</span><span class="kw">:</span><span class="at"> </span><span class="ch">null</span></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a><span class="fu">channels</span><span class="kw">:</span></span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> conda-forge</span></span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> defaults</span></span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a><span class="fu">dependencies</span><span class="kw">:</span></span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> cudatoolkit=10.1</span></span>
<span id="cb7-9"><a href="#cb7-9" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> cudnn=7.6</span></span>
<span id="cb7-10"><a href="#cb7-10" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> cupti=10.1</span></span>
<span id="cb7-11"><a href="#cb7-11" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> mpi4py=3.0</span><span class="co"> # installs cuda-aware openmpi</span></span>
<span id="cb7-12"><a href="#cb7-12" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> nccl=2.4</span></span>
<span id="cb7-13"><a href="#cb7-13" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> pip=20.0</span></span>
<span id="cb7-14"><a href="#cb7-14" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> python=3.7</span></span>
<span id="cb7-15"><a href="#cb7-15" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> tensorflow-gpu=2.1</span><span class="co"> # installs tensorflow=2.1=gpu_py37h7a4bb67_0</span></span></code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="nvidia-rapids-blazingsqldatashader">NVIDIA RAPIDS (+BlazingSQL+Datashader)<a class="anchor" aria-label="anchor" href="#nvidia-rapids-blazingsqldatashader"></a></h3>
<p>As a final example let’s see how to get started with <a href="https://rapids.ai/" class="external-link">NVIDIA RAPIDS</a> (and friends!). NVIDIA
RAPIDS is a suite of open source software libraries and APIs gives you
the ability to execute end-to-end data science and analytics pipelines
entirely on GPUs (think <a href="https://pandas.pydata.org/" class="external-link">Pandas</a>
+ <a href="https://scikit-learn.org/stable/index.html" class="external-link">Scikit-learn</a>
but for GPUs instead of CPUs). In addition to RAPIDS we have also
included <a href="https://www.blazingsql.com/" class="external-link">BlazingSQL</a> in this
example environment file. BlazingSQL is an open-source SQL interface to
extract-transform-load (ETL) massive datasets directly into GPU memory
for analysis using NVIDIA RAPIDS. The environment also includes <a href="https://datashader.org/" class="external-link">Datashader</a>, a graphics pipeline
system for creating meaningful representations of large datasets quickly
and flexibly, that can be accelerated with GPUs. If you are going to do
all of your data analysis on the GPU, then you might as well do your
data visualization on the GPU too!</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">YAML<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode yaml" tabindex="0"><code class="sourceCode yaml"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="fu">name</span><span class="kw">:</span><span class="at"> </span><span class="ch">null</span><span class="at"> </span></span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a><span class="fu">channels</span><span class="kw">:</span><span class="at">  </span></span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> blazingsql</span></span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> rapidsai</span></span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> nvidia</span></span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> conda-forge</span></span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> defaults</span></span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a></span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a><span class="fu">dependencies</span><span class="kw">:</span><span class="at">  </span></span>
<span id="cb8-11"><a href="#cb8-11" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> blazingsql=0.13</span></span>
<span id="cb8-12"><a href="#cb8-12" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> cudatoolkit=10.1</span></span>
<span id="cb8-13"><a href="#cb8-13" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> datashader=0.10</span></span>
<span id="cb8-14"><a href="#cb8-14" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> pip=20.0</span></span>
<span id="cb8-15"><a href="#cb8-15" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> python=3.7</span></span>
<span id="cb8-16"><a href="#cb8-16" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> rapids=0.13</span></span></code></pre>
</div>
<div id="what-exactly-is-installed-when-you-install-nvidia-rapids" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="what-exactly-is-installed-when-you-install-nvidia-rapids" class="callout-inner">
<h3 class="callout-title">What exactly is installed when you install NVIDIA RAPIDS?</h3>
<div class="callout-content">
<p>Create an NVIDIA RAPIDS environment using the Conda environment file
above. Use Conda commands to inspect the complete list of packages that
have been installed. Do you recognize any of the packages?</p>
</div>
</div>
</div>
<div id="accordionSolution3" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution3" aria-expanded="false" aria-controls="collapseSolution3">
  <h4 class="accordion-header" id="headingSolution3"> Show me the solution </h4>
</button>
<div id="collapseSolution3" class="accordion-collapse collapse" aria-labelledby="headingSolution3" data-bs-parent="#accordionSolution3">
<div class="accordion-body">
<p>Use the following commands to create the environment.</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="ex">$</span> mkdir nvidia-rapids-project</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a><span class="ex">$</span> cd nvidia-rapids-project/</span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a><span class="ex">$</span> nano environment.yml <span class="co"># copy-paste the environment file contents</span></span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a><span class="ex">$</span> conda env create <span class="at">--prefix</span> ./env <span class="at">--file</span> environment.yml</span></code></pre>
</div>
<p>Use the following commands to activate the environment and list all
the packages installed.</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="ex">$</span> conda activate ./env</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a><span class="ex">$</span> conda list</span></code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="but-what-if-i-need-the-nvidia-cuda-compiler">But what if I need the NVIDIA CUDA Compiler?<a class="anchor" aria-label="anchor" href="#but-what-if-i-need-the-nvidia-cuda-compiler"></a></h2>
<hr class="half-width"><p>Way up at the beginning of this lesson I mentioned that the versions
of the NVIDIA CUDA Toolkit available via the default channels did not
include the NVIDIA CUDA Compiler (NVCC). However, if your data science
project has dependencies that require compiling custom CUDA extensions
then you will almost surely need the NVIDIA CUDA Compiler (NVCC).</p>
<p>How do you know that your project dependencies need NVCC? Most likely
you will try the standard approaches above and Conda will fail to
successfully create the environment and perhaps throw a bunch of
compiler errors. Once you know that you need NVCC, there are a couple of
ways to get the NVCC compiler installed.</p>
<div class="section level3">
<h3 id="first-try-the-cudatoolkit-dev-package">First, try the <code>cudatoolkit-dev</code> package…<a class="anchor" aria-label="anchor" href="#first-try-the-cudatoolkit-dev-package"></a></h3>
<p>The cudatoolkit-dev package available from the conda-forge channel
includes GPU-accelerated libraries, debugging and optimization tools, a
C/C++ compiler and a runtime library. This package consists of a
post-install script that downloads and installs the full CUDA toolkit
(NVCC compiler and libraries, but not the exception of CUDA
drivers).</p>
<p>While the cudatoolkit-dev packages available from conda-forge do
include NVCC, I have had difficulties getting these packages to
consistently install properly.</p>
<ul><li>Some of the available builds require manual intervention to accept
license agreements making these builds unsuitable for installing on
remote systems (which is critical functionality).</li>
<li>Some other builds seem to work on Ubuntu but not on other flavors of
Linux such as CentOS.</li>
<li>Other Conda packages that depend on CUDA will often install the
cudatoolkit package even though everything included in this package will
have already been installed via cudatoolkit-dev.</li>
</ul><p>That said, it is always worth trying the <code>cudatoolkit-dev</code>
approach first. Maybe it will work for your use case. Here is an example
that uses NVCC installed via the cudatoolkit-dev package to compile
custom extensions from <a href="https://github.com/rusty1s/pytorch_cluster" class="external-link">PyTorch Cluster</a>, a
small extension library of highly optimized graph cluster algorithms for
the use with <a href="https://pytorch.org/" class="external-link">PyTorch</a>.</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">YAML<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode yaml" tabindex="0"><code class="sourceCode yaml"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="fu">name</span><span class="kw">:</span><span class="at"> </span><span class="ch">null</span></span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a><span class="fu">channels</span><span class="kw">:</span></span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> pytorch</span></span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> conda-forge</span></span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> defaults</span></span>
<span id="cb11-7"><a href="#cb11-7" tabindex="-1"></a></span>
<span id="cb11-8"><a href="#cb11-8" tabindex="-1"></a><span class="fu">dependencies</span><span class="kw">:</span></span>
<span id="cb11-9"><a href="#cb11-9" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> cudatoolkit-dev=10.1</span></span>
<span id="cb11-10"><a href="#cb11-10" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> cxx-compiler=1.0</span></span>
<span id="cb11-11"><a href="#cb11-11" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> matplotlib=3.2</span></span>
<span id="cb11-12"><a href="#cb11-12" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> networkx=2.4</span></span>
<span id="cb11-13"><a href="#cb11-13" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> numba=0.48</span></span>
<span id="cb11-14"><a href="#cb11-14" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> pandas=1.0</span></span>
<span id="cb11-15"><a href="#cb11-15" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> pip=20.0</span></span>
<span id="cb11-16"><a href="#cb11-16" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> </span><span class="fu">pip</span><span class="kw">:</span></span>
<span id="cb11-17"><a href="#cb11-17" tabindex="-1"></a><span class="at">    </span><span class="kw">-</span><span class="at"> -r file:requirements.txt</span></span>
<span id="cb11-18"><a href="#cb11-18" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> python=3.7</span></span>
<span id="cb11-19"><a href="#cb11-19" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> pytorch=1.4</span></span>
<span id="cb11-20"><a href="#cb11-20" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> scikit-image=0.16</span></span>
<span id="cb11-21"><a href="#cb11-21" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> scikit-learn=0.22</span></span>
<span id="cb11-22"><a href="#cb11-22" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> tensorboard=2.1</span></span>
<span id="cb11-23"><a href="#cb11-23" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> torchvision=0.5</span></span></code></pre>
</div>
<p>The <code>requirements.txt</code> file referenced above contains
PyTorch Cluster and related packages such as <a href="https://github.com/rusty1s/pytorch_geometric" class="external-link">PyTorch
Geometric</a>. Here is what that file looks like.</p>
<pre class="text"><code>torch-scatter==2.0.*
torch-sparse==0.6.*
torch-spline-conv==1.2.*
torch-cluster==1.5.*
torch-geometric==1.4.*

# make sure the following are re-compiled if environment is re-built
--no-binary=torch-scatter
--no-binary=torch-sparse
--no-binary=torch-spline-conv
--no-binary=torch-cluster
--no-binary=torch-geometric</code></pre>
<p>The use of the <code>--no-binary</code> option here insures that the
packages with custom extensions will be re-built whenever the
environment is re-built which helps increase the reproducibility of the
environment build process when porting from workstations to remote
clusters that might have different OS.</p>
</div>
<div class="section level3">
<h3 id="if-that-doesnt-work-then-use-the-nvcc_linux-64-meta-package">…if that doesn’t work, then use the <code>nvcc_linux-64</code>
meta-package<a class="anchor" aria-label="anchor" href="#if-that-doesnt-work-then-use-the-nvcc_linux-64-meta-package"></a></h3>
<p>The most robust approach to obtain NVCC and still use Conda to manage
all the other dependencies is to install the NVIDIA CUDA Toolkit on your
system and then install a meta-package nvcc_linux-64 from conda-forge
which configures your Conda environment to use the NVCC installed on
your system together with the other CUDA Toolkit components installed
inside the Conda environment. While we have found this approach to be
more robust then relying on <code>cudatoolkit-dev</code>, this approach
is more involved as it requires installing a <a href="https://developer.nvidia.com/cuda-toolkit-archive" class="external-link">particular
version</a> of the NVIDIA CUDA Toolkit on your system first.</p>
<p>In order to demonstrate how to use the <code>nvcc_linux-64</code>
meta-package approach we will show how to build a Conda environment for
deep learning projects that use Horovod to enable distributed training
across multiple GPUs (either on the same node or spread across multiple
nodes).</p>
<p><a href="https://github.com/horovod/horovod" class="external-link">Horovod</a> is an
open-source distributed training framework for <a href="https://www.tensorflow.org/" class="external-link">TensorFlow</a>, <a href="https://keras.io/" class="external-link">Keras</a>, <a href="https://pytorch.org/" class="external-link">PyTorch</a>, and <a href="https://mxnet.incubator.apache.org/" class="external-link">Apache MXNet</a>. Originally
developed by Uber for in-house use, Horovod was open sourced a couple of
years ago and is now an official <a href="https://lfai.foundation/" class="external-link">Linux Foundation AI (LFAI)</a>
project.</p>
<div class="section level4">
<h4 id="typical-environment-yml-file">Typical <code>environment.yml</code> file<a class="anchor" aria-label="anchor" href="#typical-environment-yml-file"></a></h4>
<p>Let’s checkout the <code>environment.yml</code> file. You can find
this <code>environment.yml</code> file on GitHub as a part of a <a href="https://github.com/kaust-vislab/horovod-gpu-data-science-project" class="external-link">template
repository</a> to help you get started with Horovod.</p>
<div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">YAML<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode yaml" tabindex="0"><code class="sourceCode yaml"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="fu">name</span><span class="kw">:</span><span class="at"> </span><span class="ch">null</span></span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a><span class="fu">channels</span><span class="kw">:</span></span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> pytorch</span></span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> conda-forge</span></span>
<span id="cb13-6"><a href="#cb13-6" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> defaults</span></span>
<span id="cb13-7"><a href="#cb13-7" tabindex="-1"></a></span>
<span id="cb13-8"><a href="#cb13-8" tabindex="-1"></a><span class="fu">dependencies</span><span class="kw">:</span></span>
<span id="cb13-9"><a href="#cb13-9" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> bokeh=1.4</span></span>
<span id="cb13-10"><a href="#cb13-10" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> cmake=3.16</span><span class="co"> # insures that Gloo library extensions will be built</span></span>
<span id="cb13-11"><a href="#cb13-11" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> cudnn=7.6</span></span>
<span id="cb13-12"><a href="#cb13-12" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> cupti=10.1</span></span>
<span id="cb13-13"><a href="#cb13-13" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> cxx-compiler=1.0</span><span class="co"> # insures C and C++ compilers are available</span></span>
<span id="cb13-14"><a href="#cb13-14" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> jupyterlab=1.2</span></span>
<span id="cb13-15"><a href="#cb13-15" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> mpi4py=3.0</span><span class="co"> # installs cuda-aware openmpi</span></span>
<span id="cb13-16"><a href="#cb13-16" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> nccl=2.5</span></span>
<span id="cb13-17"><a href="#cb13-17" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> nodejs=13</span></span>
<span id="cb13-18"><a href="#cb13-18" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> nvcc_linux-64=10.1</span><span class="co"> # configures environment to be "cuda-aware"</span></span>
<span id="cb13-19"><a href="#cb13-19" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> pip=20.0</span></span>
<span id="cb13-20"><a href="#cb13-20" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> </span><span class="fu">pip</span><span class="kw">:</span></span>
<span id="cb13-21"><a href="#cb13-21" tabindex="-1"></a><span class="at">    </span><span class="kw">-</span><span class="at"> mxnet-cu101mkl==1.6.*</span><span class="co"> # MXNET is installed prior to horovod</span></span>
<span id="cb13-22"><a href="#cb13-22" tabindex="-1"></a><span class="at">    </span><span class="kw">-</span><span class="at"> -r file:requirements.txt</span></span>
<span id="cb13-23"><a href="#cb13-23" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> python=3.7</span></span>
<span id="cb13-24"><a href="#cb13-24" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> pytorch=1.4</span></span>
<span id="cb13-25"><a href="#cb13-25" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> tensorboard=2.1</span></span>
<span id="cb13-26"><a href="#cb13-26" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> tensorflow-gpu=2.1</span></span>
<span id="cb13-27"><a href="#cb13-27" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> torchvision=0.5</span></span></code></pre>
</div>
<p>Take note of the channel priorities: <code>pytorch</code> is given
highest priority in order to insure that the official PyTorch binary is
installed (and not the binaries available on <code>conda-forge</code>).
There are also a few things worth noting about the dependencies. Even
though you have installed the NVIDIA CUDA Toolkit manually you can still
use Conda to manage the other required CUDA components such as
<code>cudnn</code> and <code>nccl</code> (and the optional
<code>cupti</code>).</p>
<ul><li>We use two meta-packages, <code>cxx-compiler</code> and
<code>nvcc_linux-64</code>, to make sure that suitable C, and C++
compilers are installed and that the resulting Conda environment is
aware of the manually installed CUDA Toolkit.</li>
<li>Horovod requires some controller library to coordinate work between
the various Horovod processes. Typically this will be some MPI
implementation such as OpenMPI. However, rather than specifying the
<code>openmpi</code> package directly, opt for <code>mpi4py</code> Conda
package which will install a CUDA-aware build of OpenMPI (assuming it is
supported by your hardware).</li>
<li>Horovod also supports the Gloo collective communications library
that can be used in place of MPI. If you include <code>cmake</code> in
order to insure that the Horovod extensions for Gloo are built.</li>
</ul></div>
<div class="section level4">
<h4 id="typical-requirements-txt-file">Typical <code>requirements.txt</code> file<a class="anchor" aria-label="anchor" href="#typical-requirements-txt-file"></a></h4>
<p>The <code>requirements.txt</code> file is where all of the
dependencies, including Horovod itself, are listed for installation via
<code>pip</code>. In addition to Horovod, it is recommended to use
<code>pip</code> to install JupyterLab extensions to enable GPU and CPU
resource monitoring via <a href="https://github.com/rapidsai/jupyterlab-nvdashboard" class="external-link"><code>jupyterlab-nvdashboard</code></a>
and <a href="https://www.tensorflow.org/tensorboard/" class="external-link">Tensorboard</a>
support via <a href="https://github.com/chaoleili/jupyterlab_tensorboard" class="external-link"><code>jupyter-tensorboard</code></a>.
Note the use of the <code>--no-binary</code> option at the end of the
file. Including this option insures that Horovod will be re-built
whenever the Conda environment is re-built.</p>
<pre class="text"><code>horovod==0.19.*
jupyterlab-nvdashboard==0.2.*
jupyter-tensorboard==0.2.*

# make sure horovod is re-compiled if environment is re-built
--no-binary=horovod</code></pre>
</div>
<div class="section level4">
<h4 id="creating-the-conda-environment">Creating the Conda environment<a class="anchor" aria-label="anchor" href="#creating-the-conda-environment"></a></h4>
<p>You can create the Conda environment in a sub-directory
<code>env</code> of your project directory by running the following
commands. By default Horovod will try and build extensions for all
detected frameworks. See the <a href="https://horovod.readthedocs.io/en/stable/" class="external-link">Horovod
documentation</a> on for the details on additional environment variables
that can be set prior to building Horovod.</p>
<div class="codewrapper sourceCode" id="cb15">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a><span class="bu">export</span> <span class="va">ENV_PREFIX</span><span class="op">=</span><span class="va">$PWD</span>/env</span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a><span class="bu">export</span> <span class="va">HOROVOD_CUDA_HOME</span><span class="op">=</span><span class="va">$CUDA_HOME</span></span>
<span id="cb15-3"><a href="#cb15-3" tabindex="-1"></a><span class="bu">export</span> <span class="va">HOROVOD_NCCL_HOME</span><span class="op">=</span><span class="va">$ENV_PREFIX</span></span>
<span id="cb15-4"><a href="#cb15-4" tabindex="-1"></a><span class="bu">export</span> <span class="va">HOROVOD_GPU_OPERATIONS</span><span class="op">=</span>NCCL</span>
<span id="cb15-5"><a href="#cb15-5" tabindex="-1"></a><span class="ex">conda</span> env create <span class="at">--prefix</span> <span class="va">$ENV_PREFIX</span> <span class="at">--file</span> environment.yml <span class="at">--force</span></span></code></pre>
</div>
<div id="wrap-complex-conda-environment-builds-in-a-script" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="wrap-complex-conda-environment-builds-in-a-script" class="callout-inner">
<h3 class="callout-title">Wrap complex Conda environment builds in a script!</h3>
<div class="callout-content">
<p>In order to enhance reproducibility of your complex Conda build, I
typically wrap commands into a shell script called
<code>create-conda-env.sh</code>. Running the shell script will set the
Horovod build variables, create the Conda environment, activate the
Conda environment, and build JupyterLab with any additional extensions
as specified in a <code>postBuild</code> script.</p>
<div class="codewrapper sourceCode" id="cb16">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a><span class="co">#!/bin/bash --login</span></span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" tabindex="-1"></a><span class="bu">set</span> <span class="at">-e</span></span>
<span id="cb16-4"><a href="#cb16-4" tabindex="-1"></a></span>
<span id="cb16-5"><a href="#cb16-5" tabindex="-1"></a><span class="bu">export</span> <span class="va">ENV_PREFIX</span><span class="op">=</span><span class="va">$PWD</span>/env</span>
<span id="cb16-6"><a href="#cb16-6" tabindex="-1"></a><span class="bu">export</span> <span class="va">HOROVOD_CUDA_HOME</span><span class="op">=</span><span class="va">$CUDA_HOME</span></span>
<span id="cb16-7"><a href="#cb16-7" tabindex="-1"></a><span class="bu">export</span> <span class="va">HOROVOD_NCCL_HOME</span><span class="op">=</span><span class="va">$ENV_PREFIX</span></span>
<span id="cb16-8"><a href="#cb16-8" tabindex="-1"></a><span class="bu">export</span> <span class="va">HOROVOD_GPU_OPERATIONS</span><span class="op">=</span>NCCL</span>
<span id="cb16-9"><a href="#cb16-9" tabindex="-1"></a><span class="ex">conda</span> env create <span class="at">--prefix</span> <span class="va">$ENV_PREFIX</span> <span class="at">--file</span> environment.yml <span class="at">--force</span></span>
<span id="cb16-10"><a href="#cb16-10" tabindex="-1"></a><span class="ex">conda</span> activate <span class="va">$ENV_PREFIX</span></span>
<span id="cb16-11"><a href="#cb16-11" tabindex="-1"></a><span class="bu">.</span> postBuild</span></code></pre>
</div>
<p>You can put scripts inside a <code>bin</code> directory in my project
root directory. The script should be run from the project root directory
as follows.</p>
<div class="codewrapper sourceCode" id="cb17">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a><span class="ex">$</span> ./bin/create-conda-env.sh</span></code></pre>
</div>
</div>
</div>
</div>
<p>We covered a lot of ground in this lesson! We showed you how to use
<code>conda search</code> to see which versions of the NVIDIA CUDA
Toolkit and related libraries such as NCCL and cuDNN were available via
Conda. Then we walked you through example Conda environment files for
several popular data science frameworks that can use GPUs. We wrapped up
with a discussion of two different approaches for getting NVCC when your
project requires compiler custom CUDA extensions. Hopefully these ideas
will help you make the jump from CPUs to GPUs on your next data science
project!</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points</h3>
<div class="callout-content">
<ul><li>Conda can be used to manage your key GPU dependencies.</li>
<li>Use <code>conda search</code> to identify which version of CUDA
libraries are available.</li>
<li>For most projects you will not need NVCC and can use the
<code>cudatoolkit</code> package from default channels.</li>
<li>If your project does need NVCC, try <code>cudatoolkit-dev</code>
package or <code>nvcc_linux-64</code> meta-package (requires separate
NVIDIA CUDA Toolkit install).</li>
</ul></div>
</div>
</div>
</div>
</div>
</section></div> <!-- / div.lesson-content -->
    </main><!-- / main#main-content.main-content --><nav class="bottom-pagination mx-md-4" aria-label="Previous and Next Chapter"><div class="d-block d-sm-block d-md-none">
        <a class="chapter-link" href="../instructor/04-sharing-environments.html"><i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>Previous</a>
        <a class="chapter-link float-end" href="../instructor/index.html">Next<i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i></a>
      </div>
      <!-- content for large screens -->
      <div class="d-none d-sm-none d-md-block">
        <a class="chapter-link" href="../instructor/04-sharing-environments.html" rel="prev">
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>
          Previous: Sharing Environments
        </a>
        <a class="chapter-link float-end" href="../instructor/index.html" rel="next">
          Home
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i>
        </a>
      </div>
    </nav></div> <!-- / div.primary-content.col-xs-12 -->
<!-- END:   inst/pkgdown/templates/content-instructor.html-->

      </div><!--/div.row-->
      		<footer class="row footer mx-md-3"><hr><div class="col-md-6">
        <p>This lesson is subject to the <a href="CODE_OF_CONDUCT.html">Code of Conduct</a></p>
        <p>

        <a href="https://github.com/carpentries-incubator/introduction-to-conda-for-data-scientists/edit/main/episodes/05-managing-cuda-dependencies.md" class="external-link">Edit on GitHub</a>

	
        | <a href="https://github.com/carpentries-incubator/introduction-to-conda-for-data-scientists/blob/main/CONTRIBUTING.md" class="external-link">Contributing</a>
        | <a href="https://github.com/carpentries-incubator/introduction-to-conda-for-data-scientists/" class="external-link">Source</a></p>
				<p><a href="https://github.com/carpentries-incubator/introduction-to-conda-for-data-scientists/blob/main/CITATION" class="external-link">Cite</a> | <a href="mailto:david.pugh@kaust.edu.sa">Contact</a> | <a href="https://carpentries.org/about/" class="external-link">About</a></p>
			</div>
			<div class="col-md-6">

        <p>Materials licensed under <a href="LICENSE.html">CC-BY 4.0</a> by the authors</p>

        <p>Template licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/" class="external-link">CC-BY 4.0</a> by <a href="https://carpentries.org/" class="external-link">The Carpentries</a></p>
        <p>Built with <a href="https://github.com/carpentries/sandpaper/tree/0.16.10" class="external-link">sandpaper (0.16.10)</a>, <a href="https://github.com/carpentries/pegboard/tree/0.7.7" class="external-link">pegboard (0.7.7)</a>, and <a href="https://github.com/carpentries/varnish/tree/1.0.5" class="external-link">varnish (1.0.5)</a></p>
			</div>
		</footer></div> <!-- / div.container -->
	<div id="to-top">
		<a href="#top">
      <i class="search-icon" data-feather="arrow-up" role="img" aria-label="Back To Top"></i><br><!-- <span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top --><span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top
		</a>
	</div>
  <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "TrainingMaterial",
  "@id": "https://carpentries-incubator.github.io/introduction-to-conda-for-data-scientists/instructor/05-managing-cuda-dependencies.html",
  "inLanguage": "en",
  "dct:conformsTo": "https://bioschemas.org/profiles/TrainingMaterial/1.0-RELEASE",
  "description": "A Carpentries Lesson teaching foundational data and coding skills to researchers worldwide",
  "keywords": "software, data, lesson, The Carpentries",
  "name": "Managing GPU dependencies",
  "creativeWorkStatus": "active",
  "url": "https://carpentries-incubator.github.io/introduction-to-conda-for-data-scientists/instructor/05-managing-cuda-dependencies.html",
  "identifier": "https://carpentries-incubator.github.io/introduction-to-conda-for-data-scientists/instructor/05-managing-cuda-dependencies.html",
  "dateCreated": "2019-05-19",
  "dateModified": "2024-11-15",
  "datePublished": "2024-11-15"
}

  </script><script>
		feather.replace();
	</script></body></html><!-- END:   inst/pkgdown/templates/layout.html-->

